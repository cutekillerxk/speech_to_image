"""
è¯­éŸ³é­”æ³•ç”»æ¿ - ç®€åŒ–ç‰ˆ
ä¸€é”®å½•éŸ³ï¼Œè‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡
"""
import gradio as gr
from PIL import Image
import os
import time
import shutil
import json
import requests
from fastapi import FastAPI, Request, UploadFile, File
from starlette.responses import JSONResponse
import tempfile
from doubao_service import doubao_service
from history_manager import history_manager


# ç›®å½•é…ç½®
BASE_DIR = os.path.dirname(__file__)
AUDIO_DIR = os.path.join(BASE_DIR, "audio")
os.makedirs(AUDIO_DIR, exist_ok=True)

# å…¨å±€çŠ¶æ€
current_image = None
current_text = ""
current_record_id = None


def process_audio_and_generate(audio, progress=gr.Progress()):
    """
    å¤„ç†éŸ³é¢‘å¹¶è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡ï¼ˆå®Œæ•´æµç¨‹ï¼‰
    
    Args:
        audio: Gradio Audioç»„ä»¶è¿”å›çš„éŸ³é¢‘æ•°æ®
        progress: Gradioè¿›åº¦æ¡å¯¹è±¡ï¼ˆè‡ªåŠ¨æ³¨å…¥ï¼‰
        
    Returns:
        gr.update: ä½¿ç”¨ gr.update() ä¿æŒå½“å‰å›¾ç‰‡ï¼Œåªåœ¨æˆåŠŸæ—¶æ›´æ–°
    """
    global current_image, current_text, current_record_id
    
    if audio is None:
        print("âš ï¸ æœªæ£€æµ‹åˆ°éŸ³é¢‘æ•°æ®")
        # ä½¿ç”¨ gr.update() ä¿æŒå½“å‰å›¾ç‰‡
        return gr.update(value=current_image) if current_image else None
    
    try:
        # ========== é˜¶æ®µ1: éŸ³é¢‘å¤„ç† ==========
        if progress:
            progress(0.1, desc="å¼€å§‹ç”Ÿæˆ")
        progress_status = "å¼€å§‹ç”Ÿæˆ"
        print("=" * 60)
        print("ğŸš€ å¼€å§‹å¤„ç†æµç¨‹")
        print("=" * 60)
        
        audio_path = None
        
        # å¤„ç†éŸ³é¢‘æ•°æ®
        if isinstance(audio, str):
            if os.path.exists(audio):
                audio_abs = os.path.abspath(audio)
                audio_dir_abs = os.path.abspath(AUDIO_DIR)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»åœ¨ audio ç›®å½•ä¸‹
                if audio_abs.startswith(audio_dir_abs):
                    # æ–‡ä»¶å·²ç»åœ¨ audio ç›®å½•ä¸‹ï¼Œç›´æ¥ä½¿ç”¨
                    audio_path = audio_abs
                    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶å·²åœ¨ audio ç›®å½•: {audio_path}")
                else:
                    # æ–‡ä»¶ä¸åœ¨ audio ç›®å½•ä¸‹ï¼Œéœ€è¦å¤åˆ¶
                    filename = os.path.basename(audio)
                    dest_path = os.path.join(AUDIO_DIR, filename)
                    dest_abs = os.path.abspath(dest_path)
                    
                    # å¦‚æœæºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶æ˜¯åŒä¸€ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶
                    if audio_abs != dest_abs:
                        shutil.copyfile(audio, dest_path)
                    audio_path = dest_path
                    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶å·²å¤åˆ¶åˆ°: {audio_path}")
        elif isinstance(audio, tuple):
            sample_rate, audio_data = audio
            # å…ˆä¿å­˜ä¸ºä¸´æ—¶ wav æ–‡ä»¶ï¼Œç„¶åè½¬æ¢ä¸º webm
            temp_wav_path = os.path.join(AUDIO_DIR, f"temp_{int(time.time() * 1000)}.wav")
            audio_path = os.path.join(AUDIO_DIR, f"audio_{int(time.time() * 1000)}.webm")
            print(f"ğŸ“ ä¿å­˜éŸ³é¢‘åˆ°: {audio_path}")
            print(f"ğŸ“Š é‡‡æ ·ç‡: {sample_rate}, æ•°æ®å½¢çŠ¶: {audio_data.shape if hasattr(audio_data, 'shape') else 'N/A'}")
            
            # å…ˆä¿å­˜ä¸º wav æ–‡ä»¶
            try:
                import soundfile as sf
                sf.write(temp_wav_path, audio_data, sample_rate)
                print("âœ… ä½¿ç”¨ soundfile ä¿å­˜ä¸´æ—¶ wav æˆåŠŸ")
            except ImportError:
                try:
                    import wave
                    import numpy as np
                    if audio_data.dtype != np.int16:
                        if audio_data.dtype == np.float32 or audio_data.dtype == np.float64:
                            audio_data = (audio_data * 32767).astype(np.int16)
                        else:
                            audio_data = audio_data.astype(np.int16)
                    with wave.open(temp_wav_path, 'wb') as wf:
                        wf.setnchannels(1 if len(audio_data.shape) == 1 else audio_data.shape[1])
                        wf.setsampwidth(2)
                        wf.setframerate(int(sample_rate))
                        wf.writeframes(audio_data.tobytes())
                    print("âœ… ä½¿ç”¨ wave ä¿å­˜ä¸´æ—¶ wav æˆåŠŸ")
                except Exception as e:
                    print(f"âŒ éŸ³é¢‘ä¿å­˜å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return gr.update(value=current_image) if current_image else None
            
            # å°è¯•è½¬æ¢ä¸º webm æ ¼å¼
            try:
                from pydub import AudioSegment
                # åŠ è½½ wav æ–‡ä»¶å¹¶å¯¼å‡ºä¸º webm
                audio_segment = AudioSegment.from_wav(temp_wav_path)
                audio_segment.export(audio_path, format="webm")
                # åˆ é™¤ä¸´æ—¶ wav æ–‡ä»¶
                if os.path.exists(temp_wav_path):
                    os.remove(temp_wav_path)
                print("âœ… è½¬æ¢ä¸º webm æ ¼å¼æˆåŠŸ")
            except ImportError:
                # å¦‚æœæ²¡æœ‰ pydubï¼Œå°è¯•ä½¿ç”¨ ffmpeg
                try:
                    import subprocess
                    subprocess.run([
                        "ffmpeg", "-i", temp_wav_path, "-c:a", "libopus", 
                        "-b:a", "64k", audio_path, "-y"
                    ], check=True, capture_output=True)
                    # åˆ é™¤ä¸´æ—¶ wav æ–‡ä»¶
                    if os.path.exists(temp_wav_path):
                        os.remove(temp_wav_path)
                    print("âœ… ä½¿ç”¨ ffmpeg è½¬æ¢ä¸º webm æ ¼å¼æˆåŠŸ")
                except (subprocess.CalledProcessError, FileNotFoundError):
                    # å¦‚æœæ— æ³•è½¬æ¢ä¸º webmï¼Œç›´æ¥ä½¿ç”¨ wav æ–‡ä»¶
                    print("âš ï¸ æ— æ³•è½¬æ¢ä¸º webmï¼Œä½¿ç”¨ wav æ ¼å¼")
                    audio_path = temp_wav_path
                    # é‡å‘½åä¸º webmï¼ˆè™½ç„¶å®é™…æ˜¯ wavï¼Œä½† API åº”è¯¥èƒ½å¤„ç†ï¼‰
                    webm_path = audio_path.replace('.wav', '.webm')
                    shutil.move(audio_path, webm_path)
                    audio_path = webm_path
            except Exception as e:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ wav æ–‡ä»¶
                print(f"âš ï¸ è½¬æ¢ä¸º webm å¤±è´¥: {e}ï¼Œä½¿ç”¨ wav æ ¼å¼")
                audio_path = temp_wav_path
                # é‡å‘½åä¸º webmï¼ˆè™½ç„¶å®é™…æ˜¯ wavï¼Œä½† API åº”è¯¥èƒ½å¤„ç†ï¼‰
                webm_path = audio_path.replace('.wav', '.webm')
                if os.path.exists(audio_path):
                    shutil.move(audio_path, webm_path)
                    audio_path = webm_path
        else:
            print(f"âŒ ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {type(audio)}")
            return gr.update(value=current_image) if current_image else None
        
        if not audio_path or not os.path.exists(audio_path):
            print("âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return gr.update(value=current_image) if current_image else None
        
        # ========== é˜¶æ®µ2: éŸ³é¢‘è½¬æ–‡å­— ==========
        if progress:
            progress(0.3, desc="éŸ³é¢‘å¤„ç†ä¸­")
        progress_status = "éŸ³é¢‘å¤„ç†ä¸­"
        print("-" * 60)
        print("ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«")
        print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        # å¦‚æœéŸ³é¢‘æ–‡ä»¶æ˜¯ webm æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º wavï¼ˆWhisper API éœ€è¦ï¼‰
        actual_audio_path = audio_path
        temp_wav_path = None
        
        if audio_path.lower().endswith('.webm'):
            print("ğŸ”„ æ£€æµ‹åˆ° webm æ ¼å¼ï¼Œè½¬æ¢ä¸º wav æ ¼å¼ä»¥é€‚é… Whisper API...")
            conversion_success = False
            temp_wav_path = os.path.join(AUDIO_DIR, f"temp_{int(time.time() * 1000)}.wav")
            
            # æ–¹æ³•1ï¼šä¼˜å…ˆå°è¯•ç›´æ¥ä½¿ç”¨ ffmpegï¼ˆæœ€ç›´æ¥çš„æ–¹æ³•ï¼‰
            try:
                import subprocess
                # ä½¿ç”¨ ffmpeg è½¬æ¢ï¼šwebm -> wav (16kHz, å•å£°é“, PCM 16ä½)
                result = subprocess.run([
                    "ffmpeg", "-i", audio_path, "-acodec", "pcm_s16le",
                    "-ar", "16000", "-ac", "1", temp_wav_path, "-y"
                ], check=True, capture_output=True, timeout=30)
                actual_audio_path = temp_wav_path
                conversion_success = True
                print("âœ… ä½¿ç”¨ ffmpeg è½¬æ¢ä¸º wav æˆåŠŸ")
            except FileNotFoundError:
                # ffmpeg æœªæ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨ pydubï¼ˆpydub ä¹Ÿéœ€è¦ ffmpegï¼Œä½†å¯èƒ½è·¯å¾„ä¸åŒï¼‰
                try:
                    from pydub import AudioSegment
                    audio_segment = AudioSegment.from_file(audio_path, format="webm")
                    audio_segment.export(temp_wav_path, format="wav")
                    actual_audio_path = temp_wav_path
                    conversion_success = True
                    print("âœ… ä½¿ç”¨ pydub è½¬æ¢ä¸º wav æˆåŠŸ")
                except (ImportError, Exception) as e:
                    print(f"âš ï¸ pydub è½¬æ¢å¤±è´¥: {e}")
                    conversion_success = False
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
                print(f"âš ï¸ ffmpeg è½¬æ¢å¤±è´¥: {e}")
                conversion_success = False
            
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç»™å‡ºæ¸…æ™°çš„é”™è¯¯æç¤º
            if not conversion_success:
                error_msg = (
                    "âŒ æ— æ³•å°† webm è½¬æ¢ä¸º wav æ ¼å¼\n"
                    "ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š\n"
                    "   1. å®‰è£… ffmpegï¼š\n"
                    "      - Windows: ä¸‹è½½ https://ffmpeg.org/download.html\n"
                    "      - æˆ–ä½¿ç”¨: choco install ffmpeg (éœ€è¦ Chocolatey)\n"
                    "   2. å°† ffmpeg æ·»åŠ åˆ°ç³»ç»Ÿ PATH ç¯å¢ƒå˜é‡\n"
                    "   3. é‡å¯ç»ˆç«¯åé‡è¯•\n"
                    "âš ï¸ å°è¯•ç›´æ¥ä½¿ç”¨ webm æ–‡ä»¶ï¼ˆå¯èƒ½å¤±è´¥ï¼‰"
                )
                print(error_msg)
                # ä»ç„¶å°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
        
        try:
            recognized_text = doubao_service.audio_to_text(actual_audio_path)
            print(f"âœ… è¯†åˆ«æˆåŠŸ: {recognized_text}")
            
            if not recognized_text or not recognized_text.strip():
                print("âŒ è¯†åˆ«ç»“æœä¸ºç©º")
                return gr.update(value=current_image) if current_image else None
            
            current_text = recognized_text.strip()
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return gr.update(value=current_image) if current_image else None
        finally:
            # æ¸…ç†ä¸´æ—¶ wav æ–‡ä»¶
            if temp_wav_path and os.path.exists(temp_wav_path):
                try:
                    os.remove(temp_wav_path)
                    print(f"ğŸ—‘ï¸ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_wav_path}")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        # ========== é˜¶æ®µ3: æ–‡æœ¬ç”Ÿæˆå®Œæ¯• ==========
        if progress:
            progress(0.5, desc="æ–‡æœ¬ç”Ÿæˆå®Œæ¯•")
        progress_status = "æ–‡æœ¬ç”Ÿæˆå®Œæ¯•"
        print("-" * 60)
        print(f"ğŸ“ è¯†åˆ«æ–‡å­—: {current_text}")
        
        # ========== é˜¶æ®µ4: æ–‡å­—è½¬å›¾ç‰‡ ==========
        if progress:
            progress(0.6, desc="æ–‡æœ¬å¤„ç†ä¸­")
        progress_status = "æ–‡æœ¬å¤„ç†ä¸­"
        print("-" * 60)
        print("ğŸ¨ å¼€å§‹ç”Ÿæˆå›¾ç‰‡")
        print(f"ğŸ“ æç¤ºè¯: {current_text}")
        
        try:
            image, recognized_text = doubao_service.text_to_image_gemini(
                current_text,
                aspect_ratio="1:1",
                image_size="1K"
            )
            print(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ")
            print(f"ğŸ–¼ï¸ å›¾ç‰‡å°ºå¯¸: {image.size if image else 'N/A'}")
            
        except Exception as e:
            print(f"âŒ å›¾ç‰‡ç”Ÿæˆé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return gr.update(value=current_image) if current_image else None
        
        # ========== é˜¶æ®µ5: ä¿å­˜åˆ°å†å²è®°å½• ==========
        if progress:
            progress(0.9, desc="å›¾ç‰‡ç”Ÿæˆå®Œæ¯•")
        progress_status = "å›¾ç‰‡ç”Ÿæˆå®Œæ¯•"
        print("-" * 60)
        print("ğŸ’¾ ä¿å­˜åˆ°å†å²è®°å½•")
        
        try:
            record = history_manager.add_record(image, recognized_text)
            current_image = image
            current_text = recognized_text
            current_record_id = record['id']
            print(f"âœ… ä¿å­˜æˆåŠŸï¼Œè®°å½•ID: {current_record_id}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # ========== å®Œæˆ ==========
        if progress:
            progress(1.0, desc="å®Œæˆ")
        print("=" * 60)
        print("âœ… æµç¨‹å®Œæˆï¼")
        print(f"ğŸ“ æ–‡å­—: {recognized_text}")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡ID: {current_record_id}")
        print("=" * 60)
        
        # æˆåŠŸæ—¶è¿”å›æ–°å›¾ç‰‡
        return gr.update(value=image)
        
    except Exception as e:
        error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        # ä¿æŒå½“å‰å›¾ç‰‡ä¸å˜ï¼Œä½¿ç”¨ gr.update() é¿å…æ¸…ç©º
        return gr.update(value=current_image) if current_image else None


def get_previous_image():
    """è·å–ä¸Šä¸€å¼ å›¾ç‰‡"""
    global current_image, current_text, current_record_id
    
    if current_record_id is None:
        print("âš ï¸ æ²¡æœ‰å½“å‰å›¾ç‰‡")
        return None
    
    current_idx = history_manager.get_current_index(current_record_id)
    if current_idx <= 0:
        print("âš ï¸ å·²ç»æ˜¯ç¬¬ä¸€å¼ ")
        return current_image
    
    prev_record = history_manager.get_record(current_idx - 1)
    if prev_record:
        try:
            image = Image.open(prev_record['image_path'])
            current_image = image
            current_text = prev_record['text']
            current_record_id = prev_record['id']
            print(f"ğŸ“¸ åˆ‡æ¢åˆ°ä¸Šä¸€å¼ : {prev_record['text']}")
            return image
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return current_image
    
    return current_image


def get_next_image():
    """è·å–ä¸‹ä¸€å¼ å›¾ç‰‡"""
    global current_image, current_text, current_record_id
    
    if current_record_id is None:
        print("âš ï¸ æ²¡æœ‰å½“å‰å›¾ç‰‡")
        return None
    
    current_idx = history_manager.get_current_index(current_record_id)
    history = history_manager.get_history()
    
    if current_idx >= len(history) - 1:
        print("âš ï¸ å·²ç»æ˜¯æœ€åä¸€å¼ ")
        return current_image
    
    next_record = history_manager.get_record(current_idx + 1)
    if next_record:
        try:
            image = Image.open(next_record['image_path'])
            current_image = image
            current_text = next_record['text']
            current_record_id = next_record['id']
            print(f"ğŸ“¸ åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ : {next_record['text']}")
            return image
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return current_image
    
    return current_image


def init_app():
    """åˆå§‹åŒ–åº”ç”¨ï¼ŒåŠ è½½æœ€åä¸€å¼ å†å²è®°å½•"""
    global current_image, current_text, current_record_id
    
    history = history_manager.get_history()
    if history:
        last_record = history[-1]
        try:
            current_image = Image.open(last_record['image_path'])
            current_text = last_record['text']
            current_record_id = last_record['id']
            print(f"ğŸ“¸ åŠ è½½å†å²è®°å½•: {last_record['text']}")
            return current_image
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
    
    print("ğŸ‘‹ åº”ç”¨åˆå§‹åŒ–å®Œæˆ")
    return None


app = FastAPI()


@app.post("/listen_click")
async def listen_click():
    print("ğŸ›°ï¸ å‰ç«¯è§¦å‘å¼€å¯ç›‘å¬æŒ‰é’®")
    return {"status": "ok"}


@app.post("/vad_upload")
async def vad_upload(file: UploadFile = File(...)):
    """
    æ¥æ”¶å‰ç«¯ VAD å½•éŸ³ï¼ˆwebm/wavï¼‰ï¼Œä¿å­˜ä¸´æ—¶æ–‡ä»¶ï¼Œå¤ç”¨ç°æœ‰å¤„ç†é€»è¾‘
    """
    try:
        print("ğŸ›°ï¸ /vad_upload æ”¶åˆ°è¯·æ±‚")
        suffix = ".webm"
        filename = f"vad_{int(time.time() * 1000)}{suffix}"
        temp_path = os.path.join(AUDIO_DIR, filename)
        # ä¿å­˜æ–‡ä»¶
        with open(temp_path, "wb") as f:
            content = await file.read()
            f.write(content)
        print(f"ğŸ’¾ VAD éŸ³é¢‘å·²ä¿å­˜: {temp_path}")
        # ç›´æ¥ç”¨æ–‡ä»¶è·¯å¾„è¿›å…¥ç°æœ‰æµç¨‹ï¼ˆprocess_audio_and_generate æ”¯æŒè·¯å¾„ï¼‰
        process_audio_and_generate(temp_path, progress=None)
        print("âœ… VAD éŸ³é¢‘å¤„ç†å®Œæˆ")
        return {"status": "ok"}
    except Exception as e:
        print(f"âŒ VAD ä¸Šä¼ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse({"status": "error", "msg": str(e)}, status_code=500)


# åˆ›å»ºGradioç•Œé¢ï¼ˆå·¦å³å¸ƒå±€ï¼šå·¦ä¾§æ ‡é¢˜+æŒ‰é’®ï¼Œå³ä¾§å›¾ç‰‡ï¼‰
with gr.Blocks(title="è¯­éŸ³é­”æ³•ç”»æ¿") as demo:
    with gr.Row():
        # å·¦ä¾§åˆ—ï¼šæ ‡é¢˜ + æŒ‰é’®
        with gr.Column(scale=1):
            gr.Markdown("## è¯­éŸ³é­”æ³•ç”»æ¿", elem_classes="title")
            prev_btn = gr.Button("â¬…ï¸ ä¸Šä¸€å¼ ", size="lg")
            next_btn = gr.Button("â¡ï¸ ä¸‹ä¸€å¼ ", size="lg")
            listen_btn = gr.Button("ğŸ™ï¸ å¼€å¯ç›‘å¬", variant="primary", size="lg", elem_id="listen-btn")
            gr.Markdown(
                "<div id='vad-status'>æœªç›‘å¬</div>",
                elem_id="vad-status-container"
            )
        # å³ä¾§åˆ—ï¼šå›¾ç‰‡å±•ç¤ºåŒºåŸŸï¼ˆå æ®ä¸»è¦å®½åº¦ï¼‰
        with gr.Column(scale=4):
            image_output = gr.Image(
                label="",
                type="pil",
                height=700,
                show_label=False
            )
    
    # ä¸Šä¸€å¼ /ä¸‹ä¸€å¼ æŒ‰é’®
    prev_btn.click(
        fn=get_previous_image,
        inputs=[],
        outputs=[image_output]
    )
    
    next_btn.click(
        fn=get_next_image,
        inputs=[],
        outputs=[image_output]
    )
    
    # æ³¨å…¥å‰ç«¯JSï¼Œå®Œæˆ VAD è‡ªåŠ¨å½•åˆ¶ä¸ä¸Šä¼ 
    # Gradio çš„ js å‚æ•°å¿…é¡»æ˜¯å‡½æ•°è¡¨è¾¾å¼ï¼Œä¸èƒ½æ˜¯é¡¶å±‚è¯­å¥
    vad_js = """
() => {
  // æ‰€æœ‰å˜é‡æŒ‚åˆ° windowï¼Œé¿å… Gradio AsyncFunction è§£æé—®é¢˜
  window.vadState = window.vadState || {};
  window.vadState.statusDiv = null;
  window.vadState.audioContext = null;
  window.vadState.mediaStream = null;
  window.vadState.analyser = null;
  window.vadState.processor = null;
  window.vadState.recorder = null;
  window.vadState.isListening = false;
  window.vadState.isRecording = false;
  window.vadState.chunks = [];
  window.vadState.silenceStart = null;

  window.vadConfig = {
    THRESHOLD: 0.08,
    SILENCE_THRESHOLD: 0.03,
    SILENCE_DURATION: 1000
  };

  window.vadSetStatus = function (text) {
    if (window.vadState.statusDiv) {
      window.vadState.statusDiv.innerText = text;
    }
    console.log('[VAD]', text);
  };

  window.vadBindButton = function () {
    window.vadState.statusDiv = document.getElementById('vad-status');
    var btn = document.getElementById('listen-btn');

    if (!btn) {
      console.warn('[VAD] listen-btn not found');
      return;
    }
    if (btn._vad_bound) return;

    btn.addEventListener('click', function () {
      fetch('/listen_click', { method: 'POST' }).catch(function () {});
      window.vadStartListening();
    });
    btn._vad_bound = true;
    window.vadSetStatus('ç‚¹å‡»å¼€å¯ç›‘å¬');
  };

  window.vadStartListening = function () {
    if (window.vadState.isListening) return;

    window.vadSetStatus('ç”³è¯·éº¦å…‹é£æƒé™...');
    navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {
      window.vadState.mediaStream = stream;

      window.vadState.audioContext = new AudioContext();
      window.vadState.audioContext.resume();

      var sourceNode =
        window.vadState.audioContext.createMediaStreamSource(stream);
      window.vadState.analyser =
        window.vadState.audioContext.createAnalyser();
      window.vadState.analyser.fftSize = 2048;

      window.vadState.processor =
        window.vadState.audioContext.createScriptProcessor(2048, 1, 1);

      sourceNode.connect(window.vadState.analyser);
      window.vadState.analyser.connect(window.vadState.processor);
      window.vadState.processor.connect(
        window.vadState.audioContext.destination
      );

      window.vadState.recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm'
      });

      window.vadState.recorder.ondataavailable = function (e) {
        if (e.data && e.data.size > 0) {
          window.vadState.chunks.push(e.data);
        }
      };

      window.vadState.recorder.onstop = function () {
        if (window.vadState.chunks.length === 0) return;

        var blob = new Blob(window.vadState.chunks, { type: 'audio/webm' });
        window.vadState.chunks = [];

        var formData = new FormData();
        formData.append('file', blob, 'audio.webm');

        fetch('/vad_upload', { method: 'POST', body: formData });
      };

      window.vadState.processor.onaudioprocess = function () {
        var data = new Uint8Array(window.vadState.analyser.fftSize);
        window.vadState.analyser.getByteTimeDomainData(data);

        var sum = 0;
        for (var i = 0; i < data.length; i++) {
          var v = data[i] / 128 - 1;
          sum += v * v;
        }
        var vol = Math.sqrt(sum / data.length);

        if (!window.vadState.isRecording && vol > window.vadConfig.THRESHOLD) {
          window.vadState.recorder.start();
          window.vadState.isRecording = true;
          window.vadState.silenceStart = null;
        } else if (window.vadState.isRecording && vol < window.vadConfig.SILENCE_THRESHOLD) {
          if (window.vadState.silenceStart === null) {
            window.vadState.silenceStart = performance.now();
          } else if (
            performance.now() - window.vadState.silenceStart >
            window.vadConfig.SILENCE_DURATION
          ) {
            window.vadState.recorder.stop();
            window.vadState.isRecording = false;
            window.vadState.silenceStart = null;
          }
        } else {
          window.vadState.silenceStart = null;
        }
      };

      window.vadState.isListening = true;
      window.vadSetStatus('ç›‘å¬ä¸­...');
    });
  };

  setTimeout(window.vadBindButton, 500);
  setTimeout(window.vadBindButton, 1500);
}
"""
    
    # åˆå§‹åŒ–å¹¶æ³¨å…¥ JavaScriptï¼ˆä½¿ç”¨ js å‚æ•°ï¼‰
    demo.load(
        fn=init_app,
        inputs=[],
        outputs=[image_output],
        js=vad_js
    )


if __name__ == "__main__":
    # æ£€æŸ¥APIå¯†é’¥
    if not doubao_service.has_api_key:
        print("âš ï¸  æœªé…ç½®API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        print("ğŸ“ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®API_KEYä»¥ä½¿ç”¨çœŸå®åŠŸèƒ½")
    
    # å°† Gradio æŒ‚è½½åˆ° FastAPI
    app = gr.mount_gradio_app(app, demo, path="/")
    print("ğŸš€ è‡ªåŠ¨ç›‘å¬ç‰ˆå¯åŠ¨ä¸­ (ç«¯å£ 7860)...")
    import uvicorn

    uvicorn.run(app, host="127.0.0.1", port=7860)
