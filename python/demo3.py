"""
è¯­éŸ³é­”æ³•ç”»æ¿ - å…¨å±å±•ç¤ºç‰ˆ
è‡ªåŠ¨ç›‘å¬ï¼Œå›¾ç‰‡å…¨å±æ˜¾ç¤º
"""
import gradio as gr
from PIL import Image
import os
import time
import shutil
import json
import requests
from fastapi import FastAPI, Request, UploadFile, File
from starlette.responses import JSONResponse
import tempfile
from doubao_service import doubao_service
from history_manager import history_manager


# ========== æ˜¾ç¤ºé…ç½®å‚æ•° ==========
DISPLAY_CONFIG = {
    # æ˜¾ç¤ºæ¨¡å¼: "fit_height", "fit_width", "fit_screen", "custom"
    "mode": "fit_height",
    # è‡ªå®šä¹‰å°ºå¯¸ï¼ˆå½“ mode="custom" æ—¶ä½¿ç”¨ï¼‰
    "custom_height": 900,  # åƒç´ 
    "custom_width": 900,  # åƒç´ 
    # å±å¹•ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œç”¨äºé¢„è®¾ï¼‰
    "screen_size": "15.6inch",  # 15.6è‹±å¯¸ï¼Œ344mm*194mm
}

# æ ¹æ®é…ç½®è®¡ç®—å›¾ç‰‡æ˜¾ç¤ºå°ºå¯¸
def get_image_size():
    """æ ¹æ®é…ç½®è¿”å›å›¾ç‰‡æ˜¾ç¤ºå°ºå¯¸"""
    mode = DISPLAY_CONFIG.get("mode", "fit_height")
    
    if mode == "custom":
        return DISPLAY_CONFIG.get("custom_height", 900), DISPLAY_CONFIG.get("custom_width", 900)
    elif mode == "fit_height":
        # ä»¥é«˜åº¦ä¸ºå‡†ï¼Œé€‚åˆ 15.6 è‹±å¯¸å±å¹•ï¼ˆé€šå¸¸ 1920x1080ï¼‰
        # ä½¿ç”¨ 90% çš„å±å¹•é«˜åº¦ï¼Œä¿æŒ 1:1 æ¯”ä¾‹
        return 900, 900  # å¯ä»¥æ ¹æ®å®é™…å±å¹•è°ƒæ•´
    elif mode == "fit_width":
        # ä»¥å®½åº¦ä¸ºå‡†
        return 1200, 1200
    else:  # fit_screen
        # å¡«æ»¡å±å¹•
        return 1000, 1000
    
    return 900, 900  # é»˜è®¤å€¼

# ç›®å½•é…ç½®
BASE_DIR = os.path.dirname(__file__)
AUDIO_DIR = os.path.join(BASE_DIR, "audio")
os.makedirs(AUDIO_DIR, exist_ok=True)

# å…¨å±€çŠ¶æ€
current_image = None
current_text = ""
current_record_id = None


def process_audio_and_generate(audio, progress=gr.Progress()):
    """
    å¤„ç†éŸ³é¢‘å¹¶è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡ï¼ˆå®Œæ•´æµç¨‹ï¼‰
    
    Args:
        audio: Gradio Audioç»„ä»¶è¿”å›çš„éŸ³é¢‘æ•°æ®
        progress: Gradioè¿›åº¦æ¡å¯¹è±¡ï¼ˆè‡ªåŠ¨æ³¨å…¥ï¼‰
        
    Returns:
        gr.update: ä½¿ç”¨ gr.update() ä¿æŒå½“å‰å›¾ç‰‡ï¼Œåªåœ¨æˆåŠŸæ—¶æ›´æ–°
    """
    global current_image, current_text, current_record_id
    
    if audio is None:
        print("âš ï¸ æœªæ£€æµ‹åˆ°éŸ³é¢‘æ•°æ®")
        # ä½¿ç”¨ gr.update() ä¿æŒå½“å‰å›¾ç‰‡
        return gr.update(value=current_image) if current_image else None
    
    try:
        # è®°å½•æ€»å¼€å§‹æ—¶é—´
        total_start_time = time.time()
        # åˆå§‹åŒ–æ—¶é—´ç»Ÿè®¡å˜é‡
        stt_duration = 0.0
        tti_duration = 0.0
        
        # ========== é˜¶æ®µ1: éŸ³é¢‘å¤„ç† ==========
        if progress:
            progress(0.1, desc="å¼€å§‹ç”Ÿæˆ")
        progress_status = "å¼€å§‹ç”Ÿæˆ"
        print("=" * 60)
        print("ğŸš€ å¼€å§‹å¤„ç†æµç¨‹")
        print("=" * 60)
        
        audio_path = None
        
        # å¤„ç†éŸ³é¢‘æ•°æ®
        if isinstance(audio, str):
            if os.path.exists(audio):
                audio_abs = os.path.abspath(audio)
                audio_dir_abs = os.path.abspath(AUDIO_DIR)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»åœ¨ audio ç›®å½•ä¸‹
                if audio_abs.startswith(audio_dir_abs):
                    # æ–‡ä»¶å·²ç»åœ¨ audio ç›®å½•ä¸‹ï¼Œç›´æ¥ä½¿ç”¨
                    audio_path = audio_abs
                    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶å·²åœ¨ audio ç›®å½•: {audio_path}")
                else:
                    # æ–‡ä»¶ä¸åœ¨ audio ç›®å½•ä¸‹ï¼Œéœ€è¦å¤åˆ¶
                    filename = os.path.basename(audio)
                    dest_path = os.path.join(AUDIO_DIR, filename)
                    dest_abs = os.path.abspath(dest_path)
                    
                    # å¦‚æœæºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶æ˜¯åŒä¸€ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶
                    if audio_abs != dest_abs:
                        shutil.copyfile(audio, dest_path)
                    audio_path = dest_path
                    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶å·²å¤åˆ¶åˆ°: {audio_path}")
        elif isinstance(audio, tuple):
            sample_rate, audio_data = audio
            # å…ˆä¿å­˜ä¸ºä¸´æ—¶ wav æ–‡ä»¶ï¼Œç„¶åè½¬æ¢ä¸º webm
            temp_wav_path = os.path.join(AUDIO_DIR, f"temp_{int(time.time() * 1000)}.wav")
            audio_path = os.path.join(AUDIO_DIR, f"audio_{int(time.time() * 1000)}.webm")
            print(f"ğŸ“ ä¿å­˜éŸ³é¢‘åˆ°: {audio_path}")
            print(f"ğŸ“Š é‡‡æ ·ç‡: {sample_rate}, æ•°æ®å½¢çŠ¶: {audio_data.shape if hasattr(audio_data, 'shape') else 'N/A'}")
            
            # å…ˆä¿å­˜ä¸º wav æ–‡ä»¶
            try:
                import soundfile as sf
                sf.write(temp_wav_path, audio_data, sample_rate)
                print("âœ… ä½¿ç”¨ soundfile ä¿å­˜ä¸´æ—¶ wav æˆåŠŸ")
            except ImportError:
                try:
                    import wave
                    import numpy as np
                    if audio_data.dtype != np.int16:
                        if audio_data.dtype == np.float32 or audio_data.dtype == np.float64:
                            audio_data = (audio_data * 32767).astype(np.int16)
                        else:
                            audio_data = audio_data.astype(np.int16)
                    with wave.open(temp_wav_path, 'wb') as wf:
                        wf.setnchannels(1 if len(audio_data.shape) == 1 else audio_data.shape[1])
                        wf.setsampwidth(2)
                        wf.setframerate(int(sample_rate))
                        wf.writeframes(audio_data.tobytes())
                    print("âœ… ä½¿ç”¨ wave ä¿å­˜ä¸´æ—¶ wav æˆåŠŸ")
                except Exception as e:
                    print(f"âŒ éŸ³é¢‘ä¿å­˜å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return gr.update(value=current_image) if current_image else None
            
            # å°è¯•è½¬æ¢ä¸º webm æ ¼å¼
            try:
                from pydub import AudioSegment
                # åŠ è½½ wav æ–‡ä»¶å¹¶å¯¼å‡ºä¸º webm
                audio_segment = AudioSegment.from_wav(temp_wav_path)
                audio_segment.export(audio_path, format="webm")
                # åˆ é™¤ä¸´æ—¶ wav æ–‡ä»¶
                if os.path.exists(temp_wav_path):
                    os.remove(temp_wav_path)
                print("âœ… è½¬æ¢ä¸º webm æ ¼å¼æˆåŠŸ")
            except ImportError:
                # å¦‚æœæ²¡æœ‰ pydubï¼Œå°è¯•ä½¿ç”¨ ffmpeg
                try:
                    import subprocess
                    subprocess.run([
                        "ffmpeg", "-i", temp_wav_path, "-c:a", "libopus", 
                        "-b:a", "64k", audio_path, "-y"
                    ], check=True, capture_output=True)
                    # åˆ é™¤ä¸´æ—¶ wav æ–‡ä»¶
                    if os.path.exists(temp_wav_path):
                        os.remove(temp_wav_path)
                    print("âœ… ä½¿ç”¨ ffmpeg è½¬æ¢ä¸º webm æ ¼å¼æˆåŠŸ")
                except (subprocess.CalledProcessError, FileNotFoundError):
                    # å¦‚æœæ— æ³•è½¬æ¢ä¸º webmï¼Œç›´æ¥ä½¿ç”¨ wav æ–‡ä»¶
                    print("âš ï¸ æ— æ³•è½¬æ¢ä¸º webmï¼Œä½¿ç”¨ wav æ ¼å¼")
                    audio_path = temp_wav_path
                    # é‡å‘½åä¸º webmï¼ˆè™½ç„¶å®é™…æ˜¯ wavï¼Œä½† API åº”è¯¥èƒ½å¤„ç†ï¼‰
                    webm_path = audio_path.replace('.wav', '.webm')
                    shutil.move(audio_path, webm_path)
                    audio_path = webm_path
            except Exception as e:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ wav æ–‡ä»¶
                print(f"âš ï¸ è½¬æ¢ä¸º webm å¤±è´¥: {e}ï¼Œä½¿ç”¨ wav æ ¼å¼")
                audio_path = temp_wav_path
                # é‡å‘½åä¸º webmï¼ˆè™½ç„¶å®é™…æ˜¯ wavï¼Œä½† API åº”è¯¥èƒ½å¤„ç†ï¼‰
                webm_path = audio_path.replace('.wav', '.webm')
                if os.path.exists(audio_path):
                    shutil.move(audio_path, webm_path)
                    audio_path = webm_path
        else:
            print(f"âŒ ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {type(audio)}")
            return gr.update(value=current_image) if current_image else None
        
        if not audio_path or not os.path.exists(audio_path):
            print("âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return gr.update(value=current_image) if current_image else None
        
        # ========== é˜¶æ®µ2: éŸ³é¢‘è½¬æ–‡å­— ==========
        if progress:
            progress(0.3, desc="éŸ³é¢‘å¤„ç†ä¸­")
        progress_status = "éŸ³é¢‘å¤„ç†ä¸­"
        print("-" * 60)
        print("ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«")
        print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        # å¦‚æœéŸ³é¢‘æ–‡ä»¶æ˜¯ webm æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º wavï¼ˆWhisper API éœ€è¦ï¼‰
        actual_audio_path = audio_path
        temp_wav_path = None
        
        if audio_path.lower().endswith('.webm'):
            print("ğŸ”„ æ£€æµ‹åˆ° webm æ ¼å¼ï¼Œè½¬æ¢ä¸º wav æ ¼å¼ä»¥é€‚é… Whisper API...")
            conversion_success = False
            temp_wav_path = os.path.join(AUDIO_DIR, f"temp_{int(time.time() * 1000)}.wav")
            
            # æ–¹æ³•1ï¼šä¼˜å…ˆå°è¯•ç›´æ¥ä½¿ç”¨ ffmpegï¼ˆæœ€ç›´æ¥çš„æ–¹æ³•ï¼‰
            try:
                import subprocess
                # ä½¿ç”¨ ffmpeg è½¬æ¢ï¼šwebm -> wav (16kHz, å•å£°é“, PCM 16ä½)
                result = subprocess.run([
                    "ffmpeg", "-i", audio_path, "-acodec", "pcm_s16le",
                    "-ar", "16000", "-ac", "1", temp_wav_path, "-y"
                ], check=True, capture_output=True, timeout=30)
                actual_audio_path = temp_wav_path
                conversion_success = True
                print("âœ… ä½¿ç”¨ ffmpeg è½¬æ¢ä¸º wav æˆåŠŸ")
            except FileNotFoundError:
                # ffmpeg æœªæ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨ pydubï¼ˆpydub ä¹Ÿéœ€è¦ ffmpegï¼Œä½†å¯èƒ½è·¯å¾„ä¸åŒï¼‰
                try:
                    from pydub import AudioSegment
                    audio_segment = AudioSegment.from_file(audio_path, format="webm")
                    audio_segment.export(temp_wav_path, format="wav")
                    actual_audio_path = temp_wav_path
                    conversion_success = True
                    print("âœ… ä½¿ç”¨ pydub è½¬æ¢ä¸º wav æˆåŠŸ")
                except (ImportError, Exception) as e:
                    print(f"âš ï¸ pydub è½¬æ¢å¤±è´¥: {e}")
                    conversion_success = False
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
                print(f"âš ï¸ ffmpeg è½¬æ¢å¤±è´¥: {e}")
                conversion_success = False
            
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç»™å‡ºæ¸…æ™°çš„é”™è¯¯æç¤º
            if not conversion_success:
                error_msg = (
                    "âŒ æ— æ³•å°† webm è½¬æ¢ä¸º wav æ ¼å¼\n"
                    "ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š\n"
                    "   1. å®‰è£… ffmpegï¼š\n"
                    "      - Windows: ä¸‹è½½ https://ffmpeg.org/download.html\n"
                    "      - æˆ–ä½¿ç”¨: choco install ffmpeg (éœ€è¦ Chocolatey)\n"
                    "   2. å°† ffmpeg æ·»åŠ åˆ°ç³»ç»Ÿ PATH ç¯å¢ƒå˜é‡\n"
                    "   3. é‡å¯ç»ˆç«¯åé‡è¯•\n"
                    "âš ï¸ å°è¯•ç›´æ¥ä½¿ç”¨ webm æ–‡ä»¶ï¼ˆå¯èƒ½å¤±è´¥ï¼‰"
                )
                print(error_msg)
                # ä»ç„¶å°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
        
        # å¼€å§‹è®¡æ—¶ï¼šéŸ³é¢‘è½¬æ–‡å­—
        stt_start_time = time.time()
        try:
            recognized_text = doubao_service.audio_to_text(actual_audio_path)
            stt_end_time = time.time()
            stt_duration = stt_end_time - stt_start_time
            
            print(f"âœ… è¯†åˆ«æˆåŠŸ: {recognized_text}")
            print(f"â±ï¸ éŸ³é¢‘è½¬æ–‡å­—è€—æ—¶: {stt_duration:.2f} ç§’")
            
            if not recognized_text or not recognized_text.strip():
                print("âŒ è¯†åˆ«ç»“æœä¸ºç©º")
                return gr.update(value=current_image) if current_image else None
            
            current_text = recognized_text.strip()
            
        except Exception as e:
            stt_end_time = time.time()
            stt_duration = stt_end_time - stt_start_time
            print(f"âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
            print(f"â±ï¸ éŸ³é¢‘è½¬æ–‡å­—è€—æ—¶: {stt_duration:.2f} ç§’ï¼ˆå¤±è´¥ï¼‰")
            import traceback
            traceback.print_exc()
            return gr.update(value=current_image) if current_image else None
        finally:
            # æ¸…ç†ä¸´æ—¶ wav æ–‡ä»¶
            if temp_wav_path and os.path.exists(temp_wav_path):
                try:
                    os.remove(temp_wav_path)
                    print(f"ğŸ—‘ï¸ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_wav_path}")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        # ========== é˜¶æ®µ3: æ–‡æœ¬ç”Ÿæˆå®Œæ¯• ==========
        if progress:
            progress(0.5, desc="æ–‡æœ¬ç”Ÿæˆå®Œæ¯•")
        progress_status = "æ–‡æœ¬ç”Ÿæˆå®Œæ¯•"
        print("-" * 60)
        print(f"ğŸ“ è¯†åˆ«æ–‡å­—: {current_text}")
        
        # ========== é˜¶æ®µ4: æ–‡å­—è½¬å›¾ç‰‡ ==========
        if progress:
            progress(0.6, desc="æ–‡æœ¬å¤„ç†ä¸­")
        progress_status = "æ–‡æœ¬å¤„ç†ä¸­"
        print("-" * 60)
        print("ğŸ¨ å¼€å§‹ç”Ÿæˆå›¾ç‰‡")
        print(f"ğŸ“ æç¤ºè¯: {current_text}")
        
        # å¼€å§‹è®¡æ—¶ï¼šæ–‡å­—è½¬å›¾ç‰‡
        tti_start_time = time.time()
        try:
            image, recognized_text = doubao_service.text_to_image_gemini(
                current_text,
                aspect_ratio="1:1",
                image_size="1K"
            )
            tti_end_time = time.time()
            tti_duration = tti_end_time - tti_start_time
            
            print(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ")
            print(f"ğŸ–¼ï¸ å›¾ç‰‡å°ºå¯¸: {image.size if image else 'N/A'}")
            print(f"â±ï¸ æ–‡å­—è½¬å›¾ç‰‡è€—æ—¶: {tti_duration:.2f} ç§’")
            
        except Exception as e:
            tti_end_time = time.time()
            tti_duration = tti_end_time - tti_start_time
            print(f"âŒ å›¾ç‰‡ç”Ÿæˆé”™è¯¯: {e}")
            print(f"â±ï¸ æ–‡å­—è½¬å›¾ç‰‡è€—æ—¶: {tti_duration:.2f} ç§’ï¼ˆå¤±è´¥ï¼‰")
            import traceback
            traceback.print_exc()
            return gr.update(value=current_image) if current_image else None
        
        # ========== é˜¶æ®µ5: ä¿å­˜åˆ°å†å²è®°å½• ==========
        if progress:
            progress(0.9, desc="å›¾ç‰‡ç”Ÿæˆå®Œæ¯•")
        progress_status = "å›¾ç‰‡ç”Ÿæˆå®Œæ¯•"
        print("-" * 60)
        print("ğŸ’¾ ä¿å­˜åˆ°å†å²è®°å½•")
        
        try:
            record = history_manager.add_record(image, recognized_text)
            current_image = image
            current_text = recognized_text
            current_record_id = record['id']
            print(f"âœ… ä¿å­˜æˆåŠŸï¼Œè®°å½•ID: {current_record_id}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # ========== å®Œæˆ ==========
        if progress:
            progress(1.0, desc="å®Œæˆ")
        
        # è®¡ç®—æ€»è€—æ—¶
        total_end_time = time.time()
        total_duration = total_end_time - total_start_time
        
        print("=" * 60)
        print("âœ… æµç¨‹å®Œæˆï¼")
        print(f"ğŸ“ æ–‡å­—: {recognized_text}")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡ID: {current_record_id}")
        print("-" * 60)
        print("â±ï¸ æ—¶é—´ç»Ÿè®¡:")
        print(f"   - éŸ³é¢‘è½¬æ–‡å­—: {stt_duration:.2f} ç§’")
        print(f"   - æ–‡å­—è½¬å›¾ç‰‡: {tti_duration:.2f} ç§’")
        print(f"   - æ€»è€—æ—¶: {total_duration:.2f} ç§’")
        print("=" * 60)
        
        # æˆåŠŸæ—¶è¿”å›æ–°å›¾ç‰‡
        return gr.update(value=image)
        
    except Exception as e:
        # è®¡ç®—æ€»è€—æ—¶ï¼ˆå³ä½¿å¤±è´¥ï¼‰
        total_end_time = time.time()
        total_duration = total_end_time - total_start_time
        
        error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        
        # è¾“å‡ºæ—¶é—´ç»Ÿè®¡ï¼ˆå³ä½¿å¤±è´¥ï¼‰
        print("-" * 60)
        print("â±ï¸ æ—¶é—´ç»Ÿè®¡ï¼ˆå¤±è´¥ï¼‰:")
        if stt_duration > 0:
            print(f"   - éŸ³é¢‘è½¬æ–‡å­—: {stt_duration:.2f} ç§’")
        else:
            print(f"   - éŸ³é¢‘è½¬æ–‡å­—: æœªå®Œæˆ")
        if tti_duration > 0:
            print(f"   - æ–‡å­—è½¬å›¾ç‰‡: {tti_duration:.2f} ç§’")
        else:
            print(f"   - æ–‡å­—è½¬å›¾ç‰‡: æœªå®Œæˆ")
        print(f"   - æ€»è€—æ—¶: {total_duration:.2f} ç§’")
        print("=" * 60)
        
        # ä¿æŒå½“å‰å›¾ç‰‡ä¸å˜ï¼Œä½¿ç”¨ gr.update() é¿å…æ¸…ç©º
        return gr.update(value=current_image) if current_image else None


def get_previous_image():
    """è·å–ä¸Šä¸€å¼ å›¾ç‰‡"""
    global current_image, current_text, current_record_id
    
    if current_record_id is None:
        print("âš ï¸ æ²¡æœ‰å½“å‰å›¾ç‰‡")
        return None
    
    current_idx = history_manager.get_current_index(current_record_id)
    if current_idx <= 0:
        print("âš ï¸ å·²ç»æ˜¯ç¬¬ä¸€å¼ ")
        return current_image
    
    prev_record = history_manager.get_record(current_idx - 1)
    if prev_record:
        try:
            image = Image.open(prev_record['image_path'])
            current_image = image
            current_text = prev_record['text']
            current_record_id = prev_record['id']
            print(f"ğŸ“¸ åˆ‡æ¢åˆ°ä¸Šä¸€å¼ : {prev_record['text']}")
            return image
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return current_image
    
    return current_image


def get_next_image():
    """è·å–ä¸‹ä¸€å¼ å›¾ç‰‡"""
    global current_image, current_text, current_record_id
    
    if current_record_id is None:
        print("âš ï¸ æ²¡æœ‰å½“å‰å›¾ç‰‡")
        return None
    
    current_idx = history_manager.get_current_index(current_record_id)
    history = history_manager.get_history()
    
    if current_idx >= len(history) - 1:
        print("âš ï¸ å·²ç»æ˜¯æœ€åä¸€å¼ ")
        return current_image
    
    next_record = history_manager.get_record(current_idx + 1)
    if next_record:
        try:
            image = Image.open(next_record['image_path'])
            current_image = image
            current_text = next_record['text']
            current_record_id = next_record['id']
            print(f"ğŸ“¸ åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ : {next_record['text']}")
            return image
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return current_image
    
    return current_image


def init_app():
    """åˆå§‹åŒ–åº”ç”¨ï¼ŒåŠ è½½æœ€åä¸€å¼ å†å²è®°å½•"""
    global current_image, current_text, current_record_id
    
    history = history_manager.get_history()
    if history:
        last_record = history[-1]
        try:
            current_image = Image.open(last_record['image_path'])
            current_text = last_record['text']
            current_record_id = last_record['id']
            print(f"ğŸ“¸ åŠ è½½å†å²è®°å½•: {last_record['text']}")
            return current_image
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
    
    print("ğŸ‘‹ åº”ç”¨åˆå§‹åŒ–å®Œæˆ")
    return None


app = FastAPI()


@app.post("/vad_upload")
async def vad_upload(file: UploadFile = File(...)):
    """
    æ¥æ”¶å‰ç«¯ VAD å½•éŸ³ï¼ˆwebm/wavï¼‰ï¼Œä¿å­˜ä¸´æ—¶æ–‡ä»¶ï¼Œå¤ç”¨ç°æœ‰å¤„ç†é€»è¾‘
    """
    try:
        print("ğŸ›°ï¸ /vad_upload æ”¶åˆ°è¯·æ±‚")
        suffix = ".webm"
        filename = f"vad_{int(time.time() * 1000)}{suffix}"
        temp_path = os.path.join(AUDIO_DIR, filename)
        # ä¿å­˜æ–‡ä»¶
        with open(temp_path, "wb") as f:
            content = await file.read()
            f.write(content)
        print(f"ğŸ’¾ VAD éŸ³é¢‘å·²ä¿å­˜: {temp_path}")
        # ç›´æ¥ç”¨æ–‡ä»¶è·¯å¾„è¿›å…¥ç°æœ‰æµç¨‹ï¼ˆprocess_audio_and_generate æ”¯æŒè·¯å¾„ï¼‰
        process_audio_and_generate(temp_path, progress=None)
        print("âœ… VAD éŸ³é¢‘å¤„ç†å®Œæˆ")
        # è¿”å›å½“å‰å›¾ç‰‡ä¿¡æ¯ï¼Œä¾›å‰ç«¯æ›´æ–°
        global current_record_id
        return {
            "status": "ok",
            "record_id": current_record_id,
            "timestamp": int(time.time() * 1000)
        }
    except Exception as e:
        print(f"âŒ VAD ä¸Šä¼ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse({"status": "error", "msg": str(e)}, status_code=500)


@app.get("/get_latest_image")
async def get_latest_image():
    """
    è·å–æœ€æ–°çš„å›¾ç‰‡ä¿¡æ¯ï¼Œç”¨äºå‰ç«¯æ›´æ–°æ˜¾ç¤º
    è¿”å›å›¾ç‰‡çš„ base64 ç¼–ç ï¼Œæ–¹ä¾¿å‰ç«¯ç›´æ¥æ˜¾ç¤º
    """
    global current_image, current_record_id
    if current_image and current_record_id:
        try:
            import base64
            from io import BytesIO
            
            # å°†å›¾ç‰‡è½¬æ¢ä¸º base64
            buffer = BytesIO()
            current_image.save(buffer, format='PNG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            history = history_manager.get_history()
            if history:
                last_record = history[-1]
                return {
                    "status": "ok",
                    "record_id": last_record['id'],
                    "image_data": f"data:image/png;base64,{img_base64}",
                    "text": last_record['text']
                }
        except Exception as e:
            print(f"âŒ è·å–å›¾ç‰‡å¤±è´¥: {e}")
            return {"status": "error", "msg": str(e)}
    return {"status": "no_image"}


# åˆ›å»ºGradioç•Œé¢ï¼ˆå…¨å±å›¾ç‰‡æ˜¾ç¤ºï¼‰
# è·å–å›¾ç‰‡æ˜¾ç¤ºå°ºå¯¸
img_height, img_width = get_image_size()

# è‡ªå®šä¹‰ CSS æ ·å¼ï¼Œè®©å›¾ç‰‡å…¨å±æ˜¾ç¤ºï¼ˆæ¨¡æ‹Ÿ Gradio å…¨å±æ•ˆæœï¼‰
custom_css = """
/* ç§»é™¤ Gradio é»˜è®¤çš„è¾¹è·å’Œå¡«å…… */
.gradio-container {
    padding: 0 !important;
    margin: 0 !important;
    max-width: 100% !important;
    height: 100vh !important;
    overflow: hidden !important;
}

/* éšè—å¯¼èˆªæ å’Œæ ‡é¢˜ */
header, footer, .gradio-header {
    display: none !important;
}

/* ä¸»å®¹å™¨å…¨å± */
.main {
    padding: 0 !important;
    margin: 0 !important;
    height: 100vh !important;
    width: 100vw !important;
    overflow: hidden !important;
}

/* å›¾ç‰‡å®¹å™¨å…¨å±ï¼ˆæ¨¡æ‹Ÿ Gradio å…¨å±æ¨¡å¼ï¼‰ */
.image-container,
.image-container > div,
.image-container .image-preview,
.image-container .image-preview > div {
    width: 100vw !important;
    height: 100vh !important;
    max-width: 100vw !important;
    max-height: 100vh !important;
    display: flex !important;
    align-items: center !important;
    justify-content: center !important;
    background-color: #000 !important;
    margin: 0 !important;
    padding: 0 !important;
    position: fixed !important;
    top: 0 !important;
    left: 0 !important;
    z-index: 9999 !important;
}

/* å›¾ç‰‡æœ¬èº«å±…ä¸­æ˜¾ç¤ºï¼Œä¿æŒæ¯”ä¾‹ */
.image-container img,
.image-container canvas {
    max-width: 100vw !important;
    max-height: 100vh !important;
    width: auto !important;
    height: auto !important;
    object-fit: contain !important;
    margin: auto !important;
}

/* éšè—å…¨å±æŒ‰é’®ï¼ˆå› ä¸ºå·²ç»æ˜¯å…¨å±äº†ï¼‰ */
.image-container button[aria-label*="fullscreen"],
.image-container button[title*="fullscreen"],
.image-container .fullscreen-button {
    display: none !important;
}
"""

with gr.Blocks(title="è¯­éŸ³é­”æ³•ç”»æ¿", css=custom_css, theme=gr.themes.Monochrome()) as demo:
    # åªæ˜¾ç¤ºå›¾ç‰‡ï¼Œå…¨å±å±•ç¤º
    image_output = gr.Image(
        label="",
        type="pil",
        height=img_height,
        width=img_width,
        show_label=False,
        container=False,
        elem_classes="image-container"
    )
    
    # æ³¨æ„ï¼šå¯¼èˆªåŠŸèƒ½å‡½æ•°ï¼ˆget_previous_image, get_next_imageï¼‰å·²ä¿ç•™
    # ä½†ä¸æ˜¾ç¤ºæŒ‰é’®ï¼Œå¦‚éœ€ä½¿ç”¨å¯é€šè¿‡é”®ç›˜å¿«æ·é”®ç­‰æ–¹å¼è§¦å‘
    
    # æ³¨å…¥å‰ç«¯JSï¼Œè‡ªåŠ¨å¯åŠ¨ VAD ç›‘å¬ï¼ˆæ— éœ€æŒ‰é’®ï¼‰
    # Gradio çš„ js å‚æ•°å¿…é¡»æ˜¯å‡½æ•°è¡¨è¾¾å¼ï¼Œä¸èƒ½æ˜¯é¡¶å±‚è¯­å¥
    vad_js = """
() => {
  // æ‰€æœ‰å˜é‡æŒ‚åˆ° windowï¼Œé¿å… Gradio AsyncFunction è§£æé—®é¢˜
  window.vadState = window.vadState || {};
  window.vadState.audioContext = null;
  window.vadState.mediaStream = null;
  window.vadState.analyser = null;
  window.vadState.processor = null;
  window.vadState.recorder = null;
  window.vadState.isListening = false;
  window.vadState.isRecording = false;
  window.vadState.chunks = [];
  window.vadState.silenceStart = null;

  window.vadConfig = {
    THRESHOLD: 0.08,
    SILENCE_THRESHOLD: 0.03,
    SILENCE_DURATION: 3000
  };

  window.vadStartListening = function () {
    if (window.vadState.isListening) {
      console.log('[VAD] å·²ç»åœ¨ç›‘å¬ä¸­');
      return;
    }

    console.log('[VAD] è‡ªåŠ¨å¯åŠ¨ç›‘å¬ï¼Œç”³è¯·éº¦å…‹é£æƒé™...');
    navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {
      window.vadState.mediaStream = stream;

      window.vadState.audioContext = new AudioContext();
      window.vadState.audioContext.resume();

      var sourceNode =
        window.vadState.audioContext.createMediaStreamSource(stream);
      window.vadState.analyser =
        window.vadState.audioContext.createAnalyser();
      window.vadState.analyser.fftSize = 2048;

      window.vadState.processor =
        window.vadState.audioContext.createScriptProcessor(2048, 1, 1);

      sourceNode.connect(window.vadState.analyser);
      window.vadState.analyser.connect(window.vadState.processor);
      window.vadState.processor.connect(
        window.vadState.audioContext.destination
      );

      window.vadState.recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm'
      });

      window.vadState.recorder.ondataavailable = function (e) {
        if (e.data && e.data.size > 0) {
          window.vadState.chunks.push(e.data);
        }
      };

      window.vadState.recorder.onstop = function () {
        if (window.vadState.chunks.length === 0) {
          console.log('[VAD] æœªå½•åˆ°éŸ³é¢‘');
          return;
        }

        var blob = new Blob(window.vadState.chunks, { type: 'audio/webm' });
        window.vadState.chunks = [];

        console.log('[VAD] ä¸Šä¼ éŸ³é¢‘ï¼Œå¤§å°:', blob.size, 'bytes');
        var formData = new FormData();
        formData.append('file', blob, 'audio.webm');

        var uploadStartTime = Date.now();
        var lastRecordId = window.vadState.lastRecordId || null;
        
        fetch('/vad_upload', { method: 'POST', body: formData })
          .then(function (response) {
            if (!response.ok) {
              throw new Error('HTTP ' + response.status);
            }
            return response.json();
          })
          .then(function (data) {
            console.log('[VAD] ä¸Šä¼ æˆåŠŸï¼Œå“åº”:', data);
            // ä¿å­˜å½“å‰è®°å½•ID
            if (data.record_id) {
              window.vadState.lastRecordId = data.record_id;
            }
            // å¼€å§‹è½®è¯¢æ£€æŸ¥æ–°å›¾ç‰‡
            if (window.checkForNewImage) {
              console.log('[VAD] å¼€å§‹æ£€æŸ¥æ–°å›¾ç‰‡ï¼Œä¸Šæ¬¡ID:', lastRecordId);
              window.checkForNewImage(uploadStartTime, lastRecordId);
            } else {
              console.error('[VAD] checkForNewImage å‡½æ•°ä¸å­˜åœ¨');
            }
          })
          .catch(function (error) {
            console.error('[VAD] ä¸Šä¼ å¤±è´¥:', error);
          });
      };

      window.vadState.processor.onaudioprocess = function () {
        var data = new Uint8Array(window.vadState.analyser.fftSize);
        window.vadState.analyser.getByteTimeDomainData(data);

        var sum = 0;
        for (var i = 0; i < data.length; i++) {
          var v = data[i] / 128 - 1;
          sum += v * v;
        }
        var vol = Math.sqrt(sum / data.length);

        if (!window.vadState.isRecording && vol > window.vadConfig.THRESHOLD) {
          window.vadState.recorder.start();
          window.vadState.isRecording = true;
          window.vadState.silenceStart = null;
          console.log('[VAD] å¼€å§‹å½•åˆ¶ï¼ŒéŸ³é‡:', vol.toFixed(3));
        } else if (window.vadState.isRecording && vol < window.vadConfig.SILENCE_THRESHOLD) {
          if (window.vadState.silenceStart === null) {
            window.vadState.silenceStart = performance.now();
          } else if (
            performance.now() - window.vadState.silenceStart >
            window.vadConfig.SILENCE_DURATION
          ) {
            window.vadState.recorder.stop();
            window.vadState.isRecording = false;
            window.vadState.silenceStart = null;
            console.log('[VAD] åœæ­¢å½•åˆ¶ï¼ˆæ£€æµ‹åˆ°é™éŸ³ï¼‰');
          }
        } else {
          window.vadState.silenceStart = null;
        }
      };

      window.vadState.isListening = true;
      console.log('[VAD] ç›‘å¬å·²å¯åŠ¨ï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥...');
    }).catch(function (error) {
      console.error('[VAD] è·å–éº¦å…‹é£æƒé™å¤±è´¥:', error);
      console.log('[VAD] è¯·åœ¨æµè§ˆå™¨ä¸­å…è®¸éº¦å…‹é£æƒé™ï¼Œç„¶ååˆ·æ–°é¡µé¢');
    });
  };

  // æ£€æŸ¥å¹¶æ›´æ–°æ–°å›¾ç‰‡
  window.checkForNewImage = function (startTime, lastRecordId) {
    console.log('[Image] å¼€å§‹æ£€æŸ¥æ–°å›¾ç‰‡ï¼Œä¸Šæ¬¡ID:', lastRecordId);
    var checkCount = 0;
    var maxChecks = 60; // æœ€å¤šæ£€æŸ¥60æ¬¡ï¼ˆçº¦30ç§’ï¼‰
    var checkInterval = 500; // æ¯500msæ£€æŸ¥ä¸€æ¬¡

    var checkIntervalId = setInterval(function () {
      checkCount++;
      console.log('[Image] æ£€æŸ¥ç¬¬', checkCount, 'æ¬¡ï¼Œä¸Šæ¬¡ID:', lastRecordId);
      
      fetch('/get_latest_image')
        .then(function (response) {
          if (!response.ok) {
            throw new Error('HTTP ' + response.status);
          }
          return response.json();
        })
        .then(function (data) {
          console.log('[Image] API è¿”å›:', data.status, 'è®°å½•ID:', data.record_id);
          
          if (data.status === 'ok' && data.record_id && data.image_data) {
            // å¦‚æœå›¾ç‰‡IDå˜åŒ–äº†ï¼Œè¯´æ˜æœ‰æ–°å›¾ç‰‡ç”Ÿæˆ
            if (!lastRecordId || data.record_id !== lastRecordId) {
              console.log('[Image] âœ… æ£€æµ‹åˆ°æ–°å›¾ç‰‡ï¼ID:', data.record_id, 'ï¼ˆä¸Šæ¬¡:', lastRecordId, 'ï¼‰');
              clearInterval(checkIntervalId);
              
              // æ›´æ–°å›¾ç‰‡æ˜¾ç¤ºï¼ˆä½¿ç”¨ base64 å›¾ç‰‡æ•°æ®ï¼‰
              if (window.updateImageDisplay) {
                window.updateImageDisplay(data.image_data);
              } else {
                console.error('[Image] updateImageDisplay å‡½æ•°ä¸å­˜åœ¨');
              }
              return;
            } else {
              console.log('[Image] å›¾ç‰‡IDæœªå˜åŒ–ï¼Œç»§ç»­ç­‰å¾…...');
            }
          } else if (data.status === 'no_image') {
            console.log('[Image] æš‚æ— å›¾ç‰‡');
          } else {
            console.log('[Image] æ•°æ®ä¸å®Œæ•´:', data);
          }

          // å¦‚æœè¶…è¿‡æœ€å¤§æ£€æŸ¥æ¬¡æ•°ï¼Œåœæ­¢æ£€æŸ¥
          if (checkCount >= maxChecks) {
            console.log('[Image] â° è¶…æ—¶ï¼Œåœæ­¢æ£€æŸ¥æ–°å›¾ç‰‡ï¼ˆå·²æ£€æŸ¥', checkCount, 'æ¬¡ï¼‰');
            clearInterval(checkIntervalId);
          }
        })
        .catch(function (error) {
          console.error('[Image] âŒ æ£€æŸ¥å›¾ç‰‡å¤±è´¥:', error);
          if (checkCount >= maxChecks) {
            console.log('[Image] è¾¾åˆ°æœ€å¤§æ£€æŸ¥æ¬¡æ•°ï¼Œåœæ­¢æ£€æŸ¥');
            clearInterval(checkIntervalId);
          }
        });
    }, checkInterval);
  };

  // æ›´æ–°å›¾ç‰‡æ˜¾ç¤º
  window.updateImageDisplay = function (imageData) {
    console.log('[Image] å¼€å§‹æ›´æ–°å›¾ç‰‡æ˜¾ç¤ºï¼Œæ•°æ®é•¿åº¦:', imageData ? imageData.length : 0);
    
    // æ–¹æ³•1: æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å›¾ç‰‡å…ƒç´ 
    var selectors = [
      '.image-container img',
      '[data-testid="image"] img',
      'img[src*="data:image"]',
      'img[src*="history"]',
      'img',
      'canvas'
    ];
    
    var imageElements = [];
    selectors.forEach(function (selector) {
      var elements = document.querySelectorAll(selector);
      elements.forEach(function (el) {
        if (imageElements.indexOf(el) === -1) {
          imageElements.push(el);
        }
      });
    });
    
    console.log('[Image] æ‰¾åˆ°', imageElements.length, 'ä¸ªå›¾ç‰‡å…ƒç´ ');
    
    if (imageElements.length > 0) {
      var updated = false;
      // æ›´æ–°æ‰€æœ‰å›¾ç‰‡å…ƒç´ 
      imageElements.forEach(function (element) {
        try {
          if (element.tagName === 'IMG') {
            console.log('[Image] æ›´æ–° IMG å…ƒç´ ï¼Œå½“å‰ src:', element.src.substring(0, 50));
            element.src = imageData; // ç›´æ¥ä½¿ç”¨ base64 æ•°æ®
            element.style.display = 'block';
            updated = true;
          } else if (element.tagName === 'CANVAS') {
            console.log('[Image] æ›´æ–° CANVAS å…ƒç´ ');
            // å¦‚æœæ˜¯ canvasï¼Œéœ€è¦é‡æ–°ç»˜åˆ¶
            var img = new Image();
            img.onload = function () {
              var ctx = element.getContext('2d');
              var maxWidth = element.width || window.innerWidth;
              var maxHeight = element.height || window.innerHeight;
              var scale = Math.min(maxWidth / img.width, maxHeight / img.height);
              var drawWidth = img.width * scale;
              var drawHeight = img.height * scale;
              var x = (maxWidth - drawWidth) / 2;
              var y = (maxHeight - drawHeight) / 2;
              ctx.clearRect(0, 0, element.width, element.height);
              ctx.drawImage(img, x, y, drawWidth, drawHeight);
              updated = true;
            };
            img.src = imageData;
          }
        } catch (e) {
          console.error('[Image] æ›´æ–°å…ƒç´ å¤±è´¥:', e);
        }
      });
      
      if (updated) {
        console.log('[Image] å›¾ç‰‡å·²æ›´æ–°');
        
        // é‡æ–°åº”ç”¨å…¨å±æ ·å¼
        setTimeout(function () {
          if (window.autoFullscreenImage) {
            window.autoFullscreenImage();
          }
        }, 200);
      }
    } else {
      console.warn('[Image] æœªæ‰¾åˆ°å›¾ç‰‡å…ƒç´ ï¼Œ3ç§’ååˆ·æ–°é¡µé¢');
      // å¦‚æœæ‰¾ä¸åˆ°å›¾ç‰‡å…ƒç´ ï¼Œå°è¯•åˆ·æ–°é¡µé¢
      setTimeout(function () {
        console.log('[Image] åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ–°å›¾ç‰‡');
        window.location.reload();
      }, 3000);
    }
    
    // å¤‡ç”¨æ–¹æ¡ˆï¼šå¦‚æœ3ç§’åå›¾ç‰‡è¿˜æ²¡æ›´æ–°ï¼Œå¼ºåˆ¶åˆ·æ–°é¡µé¢
    setTimeout(function () {
      var currentImages = document.querySelectorAll('img[src*="data:image"]');
      var hasNewImage = false;
      currentImages.forEach(function (img) {
        if (img.src === imageData || img.src.indexOf(imageData.substring(0, 50)) >= 0) {
          hasNewImage = true;
        }
      });
      
      if (!hasNewImage) {
        console.log('[Image] å¤‡ç”¨æ–¹æ¡ˆï¼šå¼ºåˆ¶åˆ·æ–°é¡µé¢');
        window.location.reload();
      }
    }, 3000);
  };

  // åˆå§‹åŒ–ï¼šè·å–å½“å‰è®°å½•ID
  function initRecordId() {
    fetch('/get_latest_image')
      .then(function (response) {
        return response.json();
      })
      .then(function (data) {
        if (data.status === 'ok' && data.record_id) {
          window.vadState.lastRecordId = data.record_id;
          console.log('[Image] åˆå§‹åŒ–è®°å½•ID:', data.record_id);
        }
      })
      .catch(function (error) {
        console.error('[Image] è·å–åˆå§‹è®°å½•IDå¤±è´¥:', error);
      });
  }

  // é¡µé¢åŠ è½½å®Œæˆåè‡ªåŠ¨å¯åŠ¨ç›‘å¬
  function autoStartVAD() {
    // å…ˆåˆå§‹åŒ–è®°å½•ID
    initRecordId();
    
    if (document.readyState === 'complete' || document.readyState === 'interactive') {
      // ç¨å¾®å»¶è¿Ÿï¼Œç¡®ä¿ DOM å®Œå…¨å°±ç»ª
      setTimeout(function () {
        console.log('[VAD] é¡µé¢åŠ è½½å®Œæˆï¼Œè‡ªåŠ¨å¯åŠ¨ç›‘å¬...');
        window.vadStartListening();
      }, 1000);
    } else {
      window.addEventListener('load', function () {
        setTimeout(function () {
          console.log('[VAD] é¡µé¢åŠ è½½å®Œæˆï¼Œè‡ªåŠ¨å¯åŠ¨ç›‘å¬...');
          window.vadStartListening();
        }, 1000);
      });
    }
  }

  // ç«‹å³å°è¯•å¯åŠ¨ï¼ˆå¦‚æœ DOM å·²å°±ç»ªï¼‰
  autoStartVAD();
  
  // ä¹Ÿç›‘å¬ DOMContentLoaded äº‹ä»¶
  document.addEventListener('DOMContentLoaded', function () {
    setTimeout(function () {
      if (!window.vadState.isListening) {
        console.log('[VAD] DOM å°±ç»ªï¼Œè‡ªåŠ¨å¯åŠ¨ç›‘å¬...');
        window.vadStartListening();
      }
    }, 1000);
  });

  // è‡ªåŠ¨è§¦å‘å›¾ç‰‡å…¨å±æ˜¾ç¤ºï¼ˆæŒ‚åˆ° window å¯¹è±¡ï¼Œä¾›å¤–éƒ¨è°ƒç”¨ï¼‰
  window.autoFullscreenImage = function () {
    function tryFullscreen() {
      // æ–¹æ³•1: æŸ¥æ‰¾å¹¶ç‚¹å‡»å…¨å±æŒ‰é’®
      var fullscreenButtons = document.querySelectorAll(
        'button[aria-label*="fullscreen"], button[title*="fullscreen"], button[aria-label*="å…¨å±"]'
      );
      if (fullscreenButtons.length > 0) {
        console.log('[Fullscreen] æ‰¾åˆ°å…¨å±æŒ‰é’®ï¼Œè‡ªåŠ¨ç‚¹å‡»');
        fullscreenButtons[0].click();
        return true;
      }

      // æ–¹æ³•2: æŸ¥æ‰¾å›¾ç‰‡å®¹å™¨å¹¶åº”ç”¨å…¨å±æ ·å¼
      var imageContainers = document.querySelectorAll('.image-container, [data-testid="image"]');
      imageContainers.forEach(function (container) {
        if (container) {
          container.style.position = 'fixed';
          container.style.top = '0';
          container.style.left = '0';
          container.style.width = '100vw';
          container.style.height = '100vh';
          container.style.zIndex = '9999';
          container.style.backgroundColor = '#000';
          container.style.display = 'flex';
          container.style.alignItems = 'center';
          container.style.justifyContent = 'center';
          console.log('[Fullscreen] åº”ç”¨å…¨å±æ ·å¼åˆ°å›¾ç‰‡å®¹å™¨');
        }
      });

      // æ–¹æ³•3: æŸ¥æ‰¾å›¾ç‰‡å¹¶ç¡®ä¿å…¨å±æ˜¾ç¤º
      var images = document.querySelectorAll('.image-container img, [data-testid="image"] img');
      images.forEach(function (img) {
        if (img) {
          img.style.maxWidth = '100vw';
          img.style.maxHeight = '100vh';
          img.style.width = 'auto';
          img.style.height = 'auto';
          img.style.objectFit = 'contain';
          console.log('[Fullscreen] åº”ç”¨å…¨å±æ ·å¼åˆ°å›¾ç‰‡');
        }
      });

      return false;
    }

    // é¡µé¢åŠ è½½åå°è¯•å…¨å±
    if (document.readyState === 'complete' || document.readyState === 'interactive') {
      setTimeout(tryFullscreen, 500);
    } else {
      window.addEventListener('load', function () {
        setTimeout(tryFullscreen, 500);
      });
    }

    // ç›‘å¬å›¾ç‰‡æ›´æ–°äº‹ä»¶ï¼ˆGradio æ›´æ–°å›¾ç‰‡æ—¶ï¼‰
    var observer = new MutationObserver(function (mutations) {
      setTimeout(tryFullscreen, 100);
    });

    // è§‚å¯Ÿæ•´ä¸ªæ–‡æ¡£çš„å˜åŒ–
    observer.observe(document.body, {
      childList: true,
      subtree: true
    });

    // ä¹Ÿç›‘å¬ DOMContentLoaded
    document.addEventListener('DOMContentLoaded', function () {
      setTimeout(tryFullscreen, 500);
    });
  }

  // å¯åŠ¨è‡ªåŠ¨å…¨å±
  window.autoFullscreenImage();
}
"""
    
    # åˆå§‹åŒ–å¹¶æ³¨å…¥ JavaScriptï¼ˆä½¿ç”¨ js å‚æ•°ï¼‰
    demo.load(
        fn=init_app,
        inputs=[],
        outputs=[image_output],
        js=vad_js
    )


if __name__ == "__main__":
    # æ£€æŸ¥APIå¯†é’¥
    if not doubao_service.has_api_key:
        print("âš ï¸  æœªé…ç½®API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        print("ğŸ“ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®API_KEYä»¥ä½¿ç”¨çœŸå®åŠŸèƒ½")
    
    # å°† Gradio æŒ‚è½½åˆ° FastAPI
    app = gr.mount_gradio_app(app, demo, path="/")
    print("ğŸš€ å…¨å±å±•ç¤ºç‰ˆå¯åŠ¨ä¸­ (ç«¯å£ 7860)...")
    print(f"ğŸ“ å›¾ç‰‡æ˜¾ç¤ºå°ºå¯¸: {img_width}x{img_height} (æ¨¡å¼: {DISPLAY_CONFIG['mode']})")
    print("ğŸ™ï¸ ç›‘å¬åŠŸèƒ½å°†åœ¨é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨å¯åŠ¨")
    print("ğŸ’¡ é¦–æ¬¡è®¿é—®éœ€è¦åœ¨æµè§ˆå™¨ä¸­å…è®¸éº¦å…‹é£æƒé™")
    import uvicorn

    uvicorn.run(app, host="127.0.0.1", port=7860)
